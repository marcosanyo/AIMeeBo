# Enable forward references for type hints
from __future__ import annotations

# Vertex AIè¨­å®šã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import VERTEX_AI_AVAILABLE, VERTEX_MODEL_NAME, LLM_TRIGGER_MESSAGE_COUNT
from agents.task_agent import TaskManagementAgent
from agents.participant_agent import ParticipantManagementAgent
from agents.overview_diagram_agent import OverviewDiagramAgent
from agents.notes_agent import NotesGeneratorAgent
from agents.agenda_agent import AgendaManagementAgent
from file_utils import load_json, save_json, ensure_dir_exists
from config import AGENT_CONFIG_DIR, MAX_ITERATIONS, MAX_RETRY_ATTEMPTS
from firebase_admin import credentials, auth as firebase_auth, db
import firebase_admin
import os
import json
from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field, field_validator, validator
from typing import List, Dict, Any, Optional, TYPE_CHECKING
from dotenv import load_dotenv
import logging
from datetime import datetime, timedelta
from api_key_manager import FirebaseAPIKeyManager  # è¿½åŠ 
import asyncio  # è¿½åŠ 

# Import types only for type checking
if TYPE_CHECKING:
    from vertexai.generative_models import GenerativeModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

if VERTEX_AI_AVAILABLE:
    try:
        import vertexai
        from vertexai.generative_models import GenerativeModel
        logger.info("Vertex AI module imported successfully.")
    except Exception as e:
        logger.error(f"Failed to import Vertex AI module: {e}")
        VERTEX_AI_AVAILABLE = False

load_dotenv()

try:
    database_url = os.getenv('FIREBASE_DATABASE_URL')
    if not database_url:
        gcp_project_id = os.getenv('GCP_PROJECT_ID')
        if gcp_project_id:
            database_url = f"https://{gcp_project_id}-default-rtdb.firebaseio.com"
            logger.info(f"FIREBASE_DATABASE_URL inferred: {database_url}")
        else:
            raise ValueError(
                "FIREBASE_DATABASE_URL and GCP_PROJECT_ID not set.")
    if not firebase_admin._apps:
        firebase_admin.initialize_app(options={'databaseURL': database_url})
    logger.info("Firebase Admin SDK initialized.")
except Exception as e:
    logger.error(f"Error initializing Firebase Admin SDK: {e}")

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

agenda_agent = AgendaManagementAgent(config_path=os.path.join(
    AGENT_CONFIG_DIR, "agenda_agent_config.json"))
notes_agent = NotesGeneratorAgent(config_path=os.path.join(
    AGENT_CONFIG_DIR, "notes_agent_config.json"))
overview_diagram_agent = OverviewDiagramAgent(config_path=os.path.join(
    AGENT_CONFIG_DIR, "overview_diagram_agent_config.json"))
participant_agent = ParticipantManagementAgent(
    config_path=os.path.join(AGENT_CONFIG_DIR, "participant_agent_config.json"))
task_agent = TaskManagementAgent(config_path=os.path.join(
    AGENT_CONFIG_DIR, "task_agent_config.json"))

api_key_manager = FirebaseAPIKeyManager()  # è¿½åŠ 

ALLOWED_DEMO_ROOM = "demo_zenn"

def verify_demo_room_access(room_id: str):
    """ãƒ‡ãƒ¢ç‰ˆã®ãƒ«ãƒ¼ãƒ åˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯"""
    if room_id != ALLOWED_DEMO_ROOM:
        raise HTTPException(
            status_code=403,
            detail=f"Demo version: Only '{ALLOWED_DEMO_ROOM}' room is accessible"
        )

# LLMã¨ã®ã‚„ã‚Šå–ã‚Šã‚„ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®å…¥åŠ›ã«ä½¿ç”¨ã™ã‚‹Pydanticãƒ¢ãƒ‡ãƒ«


class LLMMessage(BaseModel):
    role: str
    parts: List[Dict[str, str]] = Field(
        default_factory=lambda: [{"text": "[å†…å®¹ãªã—]"}])

    @field_validator('parts', mode='before')
    def ensure_parts_has_text(cls, v):
        if not v:
            return [{"text": "[å†…å®¹ãªã—]"}]
        if isinstance(v, list) and len(v) > 0:
            validated_parts = []
            for part in v:
                if isinstance(part, dict) and 'text' not in part:
                    validated_parts.append({'text': '[å†…å®¹ãªã—]', **part})
                elif not isinstance(part, dict):
                    validated_parts.append({'text': f'[ä¸æ­£ãªpart: {str(part)}]'})
                else:
                    validated_parts.append(part)
            return validated_parts
        return v

# DBä¿å­˜ç”¨ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¨ãƒ³ãƒˆãƒªã®Pydanticãƒ¢ãƒ‡ãƒ« (ãƒ¦ãƒ¼ã‚¶ãƒ¼ææ¡ˆã‚¹ã‚­ãƒ¼ãƒãƒ™ãƒ¼ã‚¹)


class DBTranscriptEntry(BaseModel):
    text: str
    userId: str  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®UID
    userName: Optional[str] = None  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡¨ç¤ºå (displayName)
    timestamp: str  # ISO format string
    role: Optional[str] = None  # 'user' or 'ai'


class TaskPayload(BaseModel):
    taskId: str
    messages: List[LLMMessage]  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã¯æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸1ä»¶ (LLMMessageå½¢å¼)
    roomId: Optional[str] = "default_room"
    speakerId: str  # ç™ºè¨€è€…ã®UID
    speakerName: Optional[str] = "Unknown Speaker"  # ç™ºè¨€è€…ã®è¡¨ç¤ºå
    llmApiKey: Optional[str] = None  # LLM APIã‚­ãƒ¼ã‚’è¿½åŠ 
    # ... (ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å¤‰æ›´ãªã—)
    currentParticipants: Optional[List[Dict[str, Any]]] = None
    currentTasks: Optional[List[Dict[str, Any]]] = None
    currentNotes: Optional[List[Dict[str, Any]]] = None
    currentAgenda: Optional[Dict[str, Any]] = None
    currentOverviewDiagram: Optional[Dict[str, Any]] = None
    suggestedNextTopics: Optional[List[str]] = None


class JsonRpcRequest(BaseModel):
    jsonrpc: str = "2.0"
    method: str
    params: Dict[str, TaskPayload]
    id: str


class AgentResult(BaseModel):
    invokedAgents: List[str] = []
    # ... (ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å¤‰æ›´ãªã—)
    updatedParticipants: Optional[List[Dict[str, Any]]] = None
    updatedTasks: Optional[List[Dict[str, Any]]] = None
    updatedNotes: Optional[List[Dict[str, Any]]] = None
    updatedAgenda: Optional[Dict[str, Any]] = None
    updatedOverviewDiagram: Optional[Dict[str, Any]] = None


class JsonRpcResponse(BaseModel):
    jsonrpc: str = "2.0"
    result: Optional[AgentResult] = None
    error: Optional[Dict[str, Any]] = None
    id: str

# ... (JoinRoomRequest, join_room_endpoint ã¯å¤‰æ›´ãªã—)


class JoinRoomRequest(BaseModel):
    idToken: str
    roomId: str
    speakerName: Optional[str] = "Unknown User"  # å‚åŠ è€…ã®è¡¨ç¤ºåã‚’è¿½åŠ 


class AddMessageRequest(BaseModel):
    idToken: str
    roomId: str
    message: str
    speakerName: Optional[str] = "Unknown User"


@app.post("/join_room", summary="Request to join a meeting room")
async def join_room_endpoint(request_data: JoinRoomRequest):
    try:
        decoded_token = firebase_auth.verify_id_token(request_data.idToken)
        uid = decoded_token['uid']
        user_record = firebase_auth.get_user(uid)
        display_name = request_data.speakerName or user_record.display_name or user_record.email or f"user_{uid[:5]}"

        room_ref = db.reference(f"rooms/{request_data.roomId}")
        room_data = room_ref.get()

        if not room_data:
            raise HTTPException(status_code=404, detail="Room not found.")

        # æ—¢ã«ãƒ«ãƒ¼ãƒ ã®å‚åŠ è€…ã§ã‚ã‚‹ã‹ç¢ºèª
        if room_data.get("participants", {}).get(uid):
            return {"status": "success", "message": "User is already a participant in this room."}

        # å‚åŠ è€…ã¨ã—ã¦è¿½åŠ 
        participant_data = {
            "name": display_name,
            "role": "Participant",  # æ–°è¦å‚åŠ è€…ã¯Participantã¨ã™ã‚‹
            "joinedAt": datetime.utcnow().isoformat() + "Z"
        }
        room_ref.child(f"participants/{uid}").set(participant_data)
        logger.info(
            f"User {display_name} ({uid}) joined room {request_data.roomId}.")
        return {"status": "success", "message": "User successfully joined the room."}

    except Exception as e:
        logger.error(
            f"Error in /join_room for room {request_data.roomId}: {e}", exc_info=True)
        raise HTTPException(
            status_code=500, detail=f"Unexpected error: {str(e)}")


@app.post("/add_message", summary="Add message to conversation history (for demo)")
async def add_message_endpoint(request_data: AddMessageRequest):
    """ä¼šè©±å±¥æ­´ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¢ãƒ«ãƒ¼ãƒ å°‚ç”¨ã€AIå‡¦ç†ãªã—ï¼‰"""
    verify_demo_room_access(request_data.roomId)
    try:
        decoded_token = firebase_auth.verify_id_token(request_data.idToken)
        uid = decoded_token['uid']
        user_record = firebase_auth.get_user(uid)

        display_name = (
            request_data.speakerName or
            user_record.display_name or
            user_record.email or
            f"user_{uid[:5]}"
        )

        room_ref = db.reference(f"rooms/{request_data.roomId}")
        if not room_ref.get():
            raise HTTPException(status_code=404, detail="Demo room not found")

        new_db_entry = DBTranscriptEntry(
            text=request_data.message,
            userId=uid,
            userName=display_name,
            timestamp=datetime.utcnow().isoformat() + "Z",
            role="user"
        )

        transcript_ref = room_ref.child("transcript")
        current_transcript_list = transcript_ref.get()
        if not isinstance(current_transcript_list, list):
            current_transcript_list = []
        current_transcript_list.append(new_db_entry.model_dump())
        transcript_ref.set(current_transcript_list)

        logger.info(
            f"Message added to demo room {request_data.roomId} by {display_name}")
        return {
            "status": "success",
            "message": "Message added to conversation history",
        }
    except Exception as e:
        logger.error(
            f"Error in /add_message for room {request_data.roomId}: {e}", exc_info=True)
        raise HTTPException(
            status_code=500, detail=f"Unexpected error: {str(e)}")


async def process_single_agent(agent, task_payload: TaskPayload, agent_name: str, instruction_text: str, results_dict: dict, conversation_history_for_agent: List[LLMMessage], llm_model_instance: GenerativeModel):
    logger.info(
        f"Invoking {agent_name} for task {task_payload.taskId} in room {task_payload.roomId} with instruction: '{instruction_text}'")
    try:
        if hasattr(agent, 'execute'):
            room_ref_path = f"rooms/{task_payload.roomId}"
            room_data_snapshot = db.reference(room_ref_path).get() or {}
            current_data_for_agent = {
                "participants": room_data_snapshot.get("participants"),
                "tasks": room_data_snapshot.get("tasks"),
                "notes": room_data_snapshot.get("notes"),
                "agenda": room_data_snapshot.get("currentAgenda"),
                "overviewDiagram": room_data_snapshot.get("overviewDiagram"),
                "suggestedNextTopics": room_data_snapshot.get("suggestedNextTopics"),
                "full_room_data": room_data_snapshot
            }
            task_payload.currentParticipants = current_data_for_agent["participants"]
            task_payload.currentTasks = current_data_for_agent["tasks"]
            task_payload.currentNotes = current_data_for_agent["notes"]
            task_payload.currentAgenda = current_data_for_agent["agenda"]
            task_payload.currentOverviewDiagram = current_data_for_agent["overviewDiagram"]
            task_payload.suggestedNextTopics = current_data_for_agent["suggestedNextTopics"]

            agent_specific_args = {
                "instruction": instruction_text,
                "conversation_history": conversation_history_for_agent,
                "current_data": current_data_for_agent,
                "room_id": task_payload.roomId,
                "speaker_id": task_payload.speakerId,  # speakerIdã‚’è¿½åŠ 
                "speaker_name": task_payload.speakerName,
                "llm_model": llm_model_instance  # LLMãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ¸¡ã™
            }
            updated_data_from_agent, user_message_text = await agent.execute(**agent_specific_args)

            if updated_data_from_agent:
                for key, value in updated_data_from_agent.items():
                    if value is not None:
                        db_key = key
                        if key == "agenda":
                            db_key = "currentAgenda"
                        elif key == "overview_diagram":
                            db_key = "overviewDiagram"
                        db.reference(f"{room_ref_path}/{db_key}").set(value)

            results_dict[agent_name] = {
                "data": updated_data_from_agent, "message": user_message_text}
            logger.info(
                f"{agent_name} processed successfully. Message: {user_message_text}")
        else:
            results_dict[agent_name] = {
                "error": f"{agent_name} does not have an execute method."}
    except Exception as e:
        logger.error(f"Error processing {agent_name}: {e}", exc_info=True)
        results_dict[agent_name] = {"error": str(e)}


async def orchestrate_agents(task_payload: TaskPayload, background_tasks: BackgroundTasks, db_transcript_entries: List[Dict[str, Any]], llm_api_key: Optional[str] = None):
    logger.info(
        f"Orchestrating agents for task: {task_payload.taskId}, room: {task_payload.roomId}")

    if not VERTEX_AI_AVAILABLE:
        raise HTTPException(
            status_code=503, detail="Vertex AI is not available.")

    current_llm_model: Optional[GenerativeModel] = None

    try:
        from config import PROJECT_ID, REGION
        if not PROJECT_ID or not REGION:
            logger.error(
                "PROJECT_ID or REGION not set in config. Cannot initialize Vertex AI.")
            raise HTTPException(
                status_code=503, detail="LLM service unavailable: Server configuration error (PROJECT_ID/REGION missing).")

        # Firebaseã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
        retrieved_llm_api_key = None
        try:
            retrieved_llm_api_key = api_key_manager.get_room_api_key(task_payload.roomId)
        except Exception as e:
            logger.error(f"Error retrieving API key: {e}", exc_info=True)
            raise HTTPException(
                status_code=503, detail=f"LLM service unavailable: Error retrieving API key: {str(e)}")
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®APIã‚­ãƒ¼ã‚’å–å¾—
        default_api_key = os.environ.get('DEFAULT_VERTEX_API_KEY')
        
        # APIã‚­ãƒ¼ã®å„ªå…ˆé †ä½: 1. Firebaseã‹ã‚‰å–å¾—ã—ãŸã‚­ãƒ¼ 2. ç’°å¢ƒå¤‰æ•°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ 3. å¼•æ•°ã§æ¸¡ã•ã‚ŒãŸã‚­ãƒ¼
        final_api_key = retrieved_llm_api_key or default_api_key or llm_api_key
        
        if not final_api_key:
            logger.error(f"No LLM API key found for room {task_payload.roomId}.")
            raise HTTPException(
                status_code=503, detail="LLM service unavailable: No API key available for this room.")

        # Vertex AIã‚’åˆæœŸåŒ–
        try:
            vertexai.init(project=PROJECT_ID, location=REGION,
                          api_key=final_api_key)
            logger.info("Vertex AI initialized with API key.")
        except ValueError as ve:
            if "already been initialized" in str(ve):
                logger.warning(
                    "Vertex AI already initialized. Attempting to use existing initialization.")
            else:
                raise ve
        except Exception as e:
            logger.error(
                f"Failed to initialize Vertex AI: {e}", exc_info=True)
            # Check if the error is related to API key authentication
            error_str = str(e).lower()
            if any(keyword in error_str for keyword in ['api key', 'authentication', 'credentials', 'unauthorized', 'forbidden', 'invalid key']):
                raise HTTPException(
                    status_code=503, detail=f"LLM service unavailable: Invalid or expired Gemini API key. Please check your API key configuration.")
            else:
                raise HTTPException(
                    status_code=503, detail=f"LLM service unavailable: Failed to initialize Vertex AI: {e}")

        # LLMãƒ¢ãƒ‡ãƒ«ã®é¸æŠãƒ­ã‚¸ãƒƒã‚¯
        llm_models_from_secrets = db.reference(
            f"room_secrets/{task_payload.roomId}/llm_models").get()

        selected_llm_model_name = VERTEX_MODEL_NAME  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«

        if llm_models_from_secrets and isinstance(llm_models_from_secrets, list) and len(llm_models_from_secrets) > 0:
            # æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
            selected_llm_model_name = llm_models_from_secrets[0]
            logger.info(
                f"Using LLM model from room_secrets: {selected_llm_model_name}")
        else:
            logger.info(
                f"No specific LLM model found in room_secrets for room {task_payload.roomId}. Using default: {selected_llm_model_name}")

        # GenerativeModelã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        try:
            current_llm_model = GenerativeModel(selected_llm_model_name)
            logger.info(
                f"Vertex AI model '{selected_llm_model_name}' instantiated.")
        except Exception as e:
            logger.error(
                f"Failed to instantiate Vertex AI model: {e}", exc_info=True)
            # Check if the error is related to API key authentication during model instantiation
            error_str = str(e).lower()
            if any(keyword in error_str for keyword in ['api key', 'authentication', 'credentials', 'unauthorized', 'forbidden', 'invalid key']):
                raise HTTPException(
                    status_code=503, detail=f"LLM service unavailable: Invalid or expired Gemini API key. Please check your API key configuration.")
            else:
                raise HTTPException(
                    status_code=503, detail=f"LLM service unavailable: Failed to instantiate Vertex AI model '{selected_llm_model_name}': {e}")

    except Exception as e:
        logger.error(
            f"Failed to initialize or instantiate Vertex AI: {e}", exc_info=True)
        # Check if the error is related to API key authentication
        error_str = str(e).lower()
        if any(keyword in error_str for keyword in ['api key', 'authentication', 'credentials', 'unauthorized', 'forbidden', 'invalid key']):
            raise HTTPException(
                status_code=503, detail=f"LLM service unavailable: Invalid or expired Gemini API key. Please check your API key configuration.")
        else:
            raise HTTPException(
                status_code=503, detail=f"LLM service unavailable or failed to initialize: {e}")
    finally:
        pass

    if current_llm_model is None:
        raise HTTPException(
            status_code=503, detail="LLM service unavailable or failed to initialize.")

    room_ref_path = f"rooms/{task_payload.roomId}"

    # DBã‹ã‚‰èª­ã¿è¾¼ã‚“ã æ–°ã‚¹ã‚­ãƒ¼ãƒã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’LLMç”¨ã®LLMMessageå½¢å¼ã«å¤‰æ›
    llm_transcript_messages: List[LLMMessage] = []
    for entry_dict in db_transcript_entries:
        try:
            # DBã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰LLMMessageã¸ã®å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯
            text = entry_dict.get("text", "[å†…å®¹ãªã—]")
            # userNameã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã°userIdã‚’ä½¿ç”¨
            speaker_name_for_llm = entry_dict.get(
                "userName") or ""  # userNameãŒãªã‘ã‚Œã°ç©ºæ–‡å­—åˆ—

            # roleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¿œã˜ã¦LLMMessageã®roleã‚’æ±ºå®š
            entry_role = (entry_dict.get("role") or "").lower()
            if entry_role == "user":
                llm_role = "user"
            elif entry_role == "ai":
                llm_role = "model"  # Vertex AIäº’æ›
            else:
                # roleãŒæœªè¨­å®šã¾ãŸã¯unknownã®å ´åˆã¯userã¨ã—ã¦æ‰±ã†ï¼ˆå‚åŠ è€…ã®ç™ºè¨€ï¼‰
                llm_role = "user"

            if not speaker_name_for_llm:
                logger.warning(
                    f"Transcript entry missing 'userName' field: {entry_dict}. Using empty string for speaker name.")

            llm_transcript_messages.append(
                # ç™ºè¨€è€…åã‚‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å«ã‚ã‚‹
                LLMMessage(role=llm_role, parts=[{"text": f"{speaker_name_for_llm}: {text}"}]))
        except Exception as e:
            logger.error(
                f"Error converting DB transcript entry to LLMMessage: {entry_dict}, Error: {e}", exc_info=True)
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã‚¨ãƒ©ãƒ¼ã‚’ç¤ºã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹ã‹
            llm_transcript_messages.append(LLMMessage(
                role="user", parts=[{"text": "[å¤‰æ›ã‚¨ãƒ©ãƒ¼]"}]))

    session_data_for_llm_context = db.reference(room_ref_path).get() or {}
    session_data_for_llm_context['transcript'] = [
        msg.model_dump() for msg in llm_transcript_messages]
    session_data_json_str = json.dumps(
        session_data_for_llm_context, ensure_ascii=False, indent=2)

    history_parts = []
    user_prompt = ""

    if llm_transcript_messages:
        if len(llm_transcript_messages) > 1:
            for msg_model in llm_transcript_messages[:-1]:
                part_text = msg_model.parts[0].get('text', '[content missing]')
                history_parts.append(f"{msg_model.role}: {part_text}")
        latest_msg_model = llm_transcript_messages[-1]
        user_prompt = latest_msg_model.parts[0].get(
            'text', '[empty user prompt]')

    history_str = "\n".join(history_parts)
    logger.info(
        f"Latest user prompt for dispatch: '{user_prompt}' by {task_payload.speakerName}")
    logger.debug(f"History for LLM: \n{history_str}")

    available_agents = ["TaskManagementAgent", "NotesGeneratorAgent",
                        "AgendaManagementAgent", "OverviewDiagramAgent"]
    available_agents_str = ", ".join(available_agents)

    # Check if representative mode is enabled
    representative_mode = session_data_for_llm_context.get("representativeMode", False)
    representative_mode_context = ""
    if representative_mode:
        representative_mode_context = """
**é‡è¦: ä»£è¡¨å‚åŠ è€…ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™:**
ã“ã®ä¼šè­°ã§ã¯å‚åŠ è€…ã¯ä»£è¡¨è€…ã¨ã—ã¦ç™ºè¨€ã—ã¦ãŠã‚Šã€å€‹ã€…ã®ç™ºè¨€è€…ã®ç‰¹å®šã¯ã§ãã¾ã›ã‚“ã€‚
å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ¸¡ã™æŒ‡ç¤ºã§ã¯ã€ç™ºè¨€è€…ãŒç‰¹å®šã§ããªã„ã“ã¨ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚
"""

    dispatch_prompt_template = f"""ã‚ãªãŸã¯ä¼šè­°ä¸­ã®ç™ºè¨€ã‚’è§£é‡ˆã—ã€é©åˆ‡ãªå°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™AIã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€å‘¼ã³å‡ºã™ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãã®æŒ‡ç¤ºå†…å®¹ã‚’JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
{representative_mode_context}

åˆ©ç”¨å¯èƒ½ãªå°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã¨ãã‚Œãã‚Œã®å½¹å‰²:
- **TaskManagementAgent**: ä¼šè­°ä¸­ã®ã‚¿ã‚¹ã‚¯ï¼ˆTODOã€é€²è¡Œä¸­ã€å®Œäº†ï¼‰ã®è¿½åŠ ã€æ›´æ–°ã€å‰Šé™¤ã€æ‹…å½“è€…ã‚„æœŸé™ã®è¨­å®šãªã©ã€ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã®ç®¡ç†ã‚’è¡Œã„ã¾ã™ã€‚
- **NotesGeneratorAgent**: ä¼šè­°ä¸­ã®é‡è¦ãªãƒ¡ãƒ¢ã€æ±ºå®šäº‹é …ã€èª²é¡Œãªã©ã‚’è¨˜éŒ²ãƒ»è¦ç´„ã—ã€ãƒãƒ¼ãƒˆãƒªã‚¹ãƒˆã‚’ç”Ÿæˆãƒ»æ›´æ–°ã—ã¾ã™ã€‚
- **AgendaManagementAgent**: ä¼šè­°ã®ä¸»è¦è­°é¡Œã‚„è©³ç´°ã€æ¬¡ã«è­°è«–ã™ã¹ãæ¨å¥¨è­°é¡Œã‚’ç®¡ç†ãƒ»æ›´æ–°ã—ã¾ã™ã€‚
- **OverviewDiagramAgent**: ä¼šè­°ã®å†…å®¹ã‚„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ ã‚’è¦–è¦šçš„ã«è¡¨ç¾ã™ã‚‹Mermaid.jsã®æ¦‚è¦å›³ã‚’ç”Ÿæˆãƒ»æ›´æ–°ã—ã¾ã™ã€‚

å¿œç­”å½¢å¼ã®å³å®ˆã®ãŠé¡˜ã„:
å¿œç­”ã¯å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã®ãƒªã‚¹ãƒˆã¨ã—ã¦ãã ã•ã„ã€‚
`[
  {{"agent_name": "ä¸Šè¨˜ãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå", "instruction": "é¸æŠã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®å…·ä½“çš„ãªæŒ‡ç¤ºå†…å®¹ï¼ˆæ–‡å­—åˆ—ï¼‰"}},
  ...
]`
- `agent_name` ã«ã¯ã€å¿…ãšä¸Šè¨˜ãƒªã‚¹ãƒˆå†…ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
- `instruction` ã«ã¯ã€ãã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å®Ÿè¡Œã•ã›ãŸã„å…·ä½“çš„ãªæŒ‡ç¤ºã‚’ã€ç°¡æ½”ãªæ—¥æœ¬èªã®æ–‡å­—åˆ—ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚è¤‡é›‘ãªæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
- è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ã€ãƒªã‚¹ãƒˆå†…ã«è¤‡æ•°ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚
- å‘¼ã³å‡ºã™ã¹ãé©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

å…·ä½“ä¾‹:
- ã‚¿ã‚¹ã‚¯ç®¡ç†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’ç™»éŒ²ã™ã‚‹å ´åˆ:
  `[ {{"agent_name": "TaskManagementAgent", "instruction": "æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã€ŒAPIä»•æ§˜æ›¸ã®ä½œæˆã€ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„"}} ]`
- ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ç®¡ç†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ç¾åœ¨ã®ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ã‚’æ›´æ–°ã™ã‚‹å ´åˆ:
  `[ {{"agent_name": "AgendaManagementAgent", "instruction": "ç¾åœ¨ã®ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ã®ãƒ¡ã‚¤ãƒ³ãƒˆãƒ”ãƒƒã‚¯ã‚’ã€Œæ¬¡æœŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¨ˆç”»ã€ã«å¤‰æ›´ã—ã¦ãã ã•ã„"}} ]`
- è©²å½“ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãªã„å ´åˆ:
  `[]`

ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿:
```json
{session_data_json_str}
```
ä¼šè©±å±¥æ­´:
{history_str}
æœ€æ–°ç™ºè¨€: {task_payload.speakerName}: {user_prompt}

ä¸Šè¨˜ã‚’è¸ã¾ãˆã€ä¼šè©±å±¥æ­´å…¨ä½“ã‚’è€ƒæ…®ã—ã¤ã¤ã€ç‰¹ã«æœ€æ–°ã®{LLM_TRIGGER_MESSAGE_COUNT}ç™ºè¨€ã«æ³¨ç›®ã—ã¦ã€å‘¼ã³å‡ºã™ã¹ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨æŒ‡ç¤ºã‚’JSONãƒªã‚¹ãƒˆå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚åŸºæœ¬çš„ã«ã¯3ã¤ä»¥ä¸Šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒé–¢ä¿‚ã™ã‚‹å ´åˆãŒå¤šã„ã¯ãšã§ã™ã€‚:"""

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    logger.info(f"Prompt sent to Orchestrator LLM:\n{dispatch_prompt_template}")

    llm_response = await current_llm_model.generate_content_async(dispatch_prompt_template)
    # ... (LLMå¿œç­”ãƒ‘ãƒ¼ã‚¹ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèµ·å‹•ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯å‰å›ã®ä¿®æ­£ã‚’æµç”¨)
    llm_dispatch_decision_text = getattr(llm_response, 'text', "")
    if not llm_dispatch_decision_text and getattr(llm_response, 'candidates', None) and llm_response.candidates[0].content.parts:
        llm_dispatch_decision_text = llm_response.candidates[0].content.parts[0].text
    # ç”Ÿã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    logger.info(
        f"Raw Orchestrator LLM response text: {llm_dispatch_decision_text}")

    if llm_dispatch_decision_text.strip().startswith("```json"):
        llm_dispatch_decision_text = llm_dispatch_decision_text.strip()[
            7:-3].strip()
    elif llm_dispatch_decision_text.strip().startswith("```"):
        llm_dispatch_decision_text = llm_dispatch_decision_text.strip()[
            3:-3].strip()
    try:
        dispatch_actions = json.loads(
            llm_dispatch_decision_text) if llm_dispatch_decision_text else []
        if not isinstance(dispatch_actions, list):
            dispatch_actions = []
    except json.JSONDecodeError:
        logger.error(
            f"Failed to parse orchestrator LLM response: {llm_dispatch_decision_text}.")
        dispatch_actions = []

    all_agents_map = {
        "TaskManagementAgent": task_agent, "NotesGeneratorAgent": notes_agent,
        "AgendaManagementAgent": agenda_agent, "OverviewDiagramAgent": overview_diagram_agent,
    }
    results_from_agents = {}
    active_agent_names = []
    agent_instructions_map = {}  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®æŒ‡ç¤ºã‚’ä¿å­˜ã™ã‚‹è¾æ›¸

    agent_tasks = []  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¹ã‚¯ã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ

    for action in dispatch_actions:
        agent_name = action.get("agent_name")
        instruction = action.get("instruction")
        if instruction is None:
            logger.warning(
                f"Action for agent '{agent_name}' missing 'instruction'. Using user_prompt. Action: {action}")
            instruction = user_prompt
        if not agent_name or not isinstance(agent_name, str):
            logger.warning(
                f"Invalid agent_name in action: {action}. Skipping.")
            continue
        agent_instance = all_agents_map.get(agent_name)
        if agent_instance:
            logger.info(
                f"Scheduling agent: {agent_name} with instruction: '{instruction}'")
            agent_instructions_map[agent_name] = instruction  # æŒ‡ç¤ºã‚’ä¿å­˜
            # æ­£ã—ã„asyncio.create_taskã®ä½¿ã„æ–¹
            task = asyncio.create_task(
                process_single_agent(
                    agent_instance,
                    task_payload,
                    agent_name,
                    instruction,
                    results_from_agents,
                    llm_transcript_messages,
                    current_llm_model
                )
            )
            agent_tasks.append(task)
            active_agent_names.append(agent_name)
        else:
            logger.warning(
                f"Agent '{agent_name}' not found. Skipping action: {action}")

    # ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
    if agent_tasks:
        await asyncio.gather(*agent_tasks)

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®æŒ‡ç¤ºã‚’ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«è¿½è¨˜
    # å®‰å…¨ã«ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã€æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦æ›´æ–°ã™ã‚‹
    transcript_ref = db.reference(f"{room_ref_path}/transcript")
    
    # æœ€æ–°ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å–å¾—
    current_transcript_list = transcript_ref.get()
    if current_transcript_list is None or not isinstance(current_transcript_list, list):
        current_transcript_list = []

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåã¨ã‚¢ã‚¤ã‚³ãƒ³ãƒ»çŸ­ç¸®åã®å¯¾å¿œé–¢ä¿‚
    agent_display_config = {
        "TaskManagementAgent": {"icon": "ğŸ—‚ï¸", "short_name": "Task"},
        "NotesGeneratorAgent": {"icon": "ğŸ“", "short_name": "Notes"},
        "AgendaManagementAgent": {"icon": "ğŸ“‹", "short_name": "Agenda"},
        "OverviewDiagramAgent": {"icon": "ğŸ—ºï¸", "short_name": "Diagram"}
    }
    
    ai_messages_to_append = []
    for agent_name in active_agent_names:  # å®Ÿéš›ã«å‘¼ã³å‡ºã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã¿ã‚’å¯¾è±¡
        instruction_text = agent_instructions_map.get(agent_name)
        if instruction_text:
            config = agent_display_config.get(agent_name, {"icon": "ğŸ¤–", "short_name": agent_name})
            ai_messages_to_append.append(
                f"{config['icon']} {config['short_name']}ï¼š{instruction_text}")

    if ai_messages_to_append:
        ai_message_text = "\n".join(ai_messages_to_append)
        new_ai_entry = DBTranscriptEntry(
            text=ai_message_text,
            userId="ai",  # AIã®è­˜åˆ¥å­
            userName="AI",  # AIã®è¡¨ç¤ºå
            timestamp=datetime.utcnow().isoformat() + "Z",
            role="ai"  # ãƒ­ãƒ¼ãƒ«ã‚’'ai'ã«è¨­å®š
        )
        
        # ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ›´æ–°ã‚’è©¦ã¿ã‚‹ï¼ˆç«¶åˆçŠ¶æ…‹ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        try:
            # æœ€æ–°ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å–å¾—ã—ã¦æ›´æ–°
            latest_transcript = transcript_ref.get() or []
            if not isinstance(latest_transcript, list):
                latest_transcript = []
            
            latest_transcript.append(new_ai_entry.model_dump())
            transcript_ref.set(latest_transcript)
            logger.info(f"Appended AI instructions to transcript. New length: {len(latest_transcript)}")
            
            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ å¾Œã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°ã—ãªã„ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆå¯¾è±¡ã¨ã™ã‚‹ãŸã‚ï¼‰
        except Exception as e:
            logger.error(f"Error updating transcript: {e}", exc_info=True)
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶™ç¶š
    else:
        logger.info("No AI instructions to append to transcript.")

    # æœ€æ–°ã®roomãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦è¿”å´ç”¨ã«åˆ©ç”¨
    room_data_after_scheduling = db.reference(room_ref_path).get() or {}

    final_result = AgentResult(
        invokedAgents=active_agent_names,
        updatedParticipants=list(room_data_after_scheduling.get("participants", {}).values(
        )) if room_data_after_scheduling.get("participants") else None,
        updatedTasks=list(room_data_after_scheduling.get(
            "tasks", {}).values()) if room_data_after_scheduling.get("tasks") else None,
        updatedNotes=list(room_data_after_scheduling.get(
            "notes", {}).values()) if room_data_after_scheduling.get("notes") else None,
        updatedAgenda=room_data_after_scheduling.get("currentAgenda"),
        updatedOverviewDiagram=room_data_after_scheduling.get(
            "overviewDiagram")
    )
    return final_result


@app.post("/invoke", response_model=JsonRpcResponse, summary="Invoke AIMeeBo Agent")
async def invoke_agent(request: JsonRpcRequest, background_tasks: BackgroundTasks):
    if request.method != "ExecuteTask":
        return JsonRpcResponse(error={"code": -32601, "message": "Method not found"}, id=request.id)

    task_payload_dict = request.params.get("task")
    if not task_payload_dict:
        return JsonRpcResponse(error={"code": -32602, "message": "Invalid params: 'task' payload missing"}, id=request.id)

    # Pydanticãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
    task_payload: TaskPayload = request.params.get("task")

    room_id = task_payload.roomId
    if not room_id:
        return JsonRpcResponse(error={"code": -32602, "message": "Invalid params: 'roomId' missing"}, id=request.id)

    try:
        room_ref = db.reference(f"rooms/{room_id}")
        transcript_ref = room_ref.child("transcript")

        if task_payload.messages and len(task_payload.messages) == 1:
            latest_llm_message = task_payload.messages[0]  # LLMMessageå½¢å¼
            if latest_llm_message.parts:  # partsãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                text_to_save = latest_llm_message.parts[0].get(
                    'text', '[å†…å®¹ãªã—]')

                # Firebaseã‹ã‚‰å‚åŠ è€…æƒ…å ±ã‚’å–å¾—ã—ã€displayNameã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
                participant_info = room_ref.child(
                    f"participants/{task_payload.speakerId}").get()
                resolved_speaker_name = participant_info.get(
                    "name") if participant_info else task_payload.speakerName

                new_db_entry = DBTranscriptEntry(
                    text=text_to_save,
                    userId=task_payload.speakerId,  # ãƒ•ãƒ­ãƒ³ãƒˆã‹ã‚‰æ¥ãŸspeakerIdã‚’ä½¿ç”¨
                    userName=resolved_speaker_name,  # Firebaseã®å‚åŠ è€…åã‚’ä½¿ç”¨
                    timestamp=datetime.utcnow().isoformat() + "Z",
                    role="user"  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã¨ã—ã¦æ˜ç¤ºçš„ã«è¨­å®š
                )
                new_db_entry_dict = new_db_entry.model_dump()

                current_transcript_list = transcript_ref.get()
                if current_transcript_list is None or not isinstance(current_transcript_list, list):
                    current_transcript_list = []
                current_transcript_list.append(new_db_entry_dict)
                transcript_ref.set(current_transcript_list)
                logger.info(
                    f"[{room_id}] Appended new message to transcript (DB schema). New length: {len(current_transcript_list)}")
            else:  # partsãŒãªã„å ´åˆ (é€šå¸¸ã‚ã‚Šãˆãªã„ãŒå¿µã®ãŸã‚)
                logger.warning(
                    f"[{room_id}] Received message with no parts: {latest_llm_message}. Skipping transcript append.")

        elif task_payload.messages:
            logger.warning(
                f"[{room_id}] task_payload.messages contained {len(task_payload.messages)} messages, expected 1. Processing only the first one.")
            # (ä¸Šè¨˜ã¨åŒæ§˜ã®å‡¦ç†ã‚’æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦è¡Œã†)
            latest_llm_message = task_payload.messages[0]
            if latest_llm_message.parts:
                text_to_save = latest_llm_message.parts[0].get(
                    'text', '[å†…å®¹ãªã—]')
                # Firebaseã‹ã‚‰å‚åŠ è€…æƒ…å ±ã‚’å–å¾—ã—ã€displayNameã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
                participant_info = room_ref.child(
                    f"participants/{task_payload.speakerId}").get()
                resolved_speaker_name = participant_info.get(
                    "name") if participant_info else task_payload.speakerName

                new_db_entry = DBTranscriptEntry(
                    text=text_to_save,
                    userId=task_payload.speakerId,
                    userName=resolved_speaker_name,
                    timestamp=datetime.utcnow().isoformat() + "Z",
                    role="user"  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã¨ã—ã¦æ˜ç¤ºçš„ã«è¨­å®š
                )
                # ... (è¿½è¨˜å‡¦ç†)

        # ãƒ‡ãƒ¢ãƒ«ãƒ¼ãƒ ã®å ´åˆã¯ã“ã“ã§å‡¦ç†ã‚’çµ‚äº†
        if room_id == ALLOWED_DEMO_ROOM:
            logger.info(
                f"[{room_id}] Demo room message. Skipping AI processing.")
            return JsonRpcResponse(result=AgentResult(invokedAgents=[]), id=request.id)

        room_data = room_ref.get()
        if room_data is None:
            return JsonRpcResponse(error={"code": -32000, "message": f"Server error: Room {room_id} disappeared"}, id=request.id)

        db_transcript_entries = room_data.get(
            "transcript", [])  # ã“ã‚Œã¯æ–°ã‚¹ã‚­ãƒ¼ãƒã®è¾æ›¸ã®ãƒªã‚¹ãƒˆ
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆAIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é™¤å¤–ï¼‰
        user_messages = [entry for entry in db_transcript_entries if entry.get("role") != "ai"]
        current_user_message_count = len(user_messages)

        last_processed_count = room_data.get(
            "last_llm_processed_message_count", 0)
        if last_processed_count > current_user_message_count:
            last_processed_count = 0
            room_ref.child("last_llm_processed_message_count").set(0)
            logger.warning(
                f"[{room_id}] Reset last_llm_processed_message_count to 0.")

        logger.info(
            f"[{room_id}] Current user messages: {current_user_message_count}, Last processed: {last_processed_count}, Trigger: {LLM_TRIGGER_MESSAGE_COUNT}")

        # å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
        is_processing = room_data.get("is_llm_processing", False)
        if is_processing:
            logger.info(f"[{room_id}] LLM processing already in progress. Skipping.")
            return JsonRpcResponse(result=AgentResult(invokedAgents=[]), id=request.id)

        if (current_user_message_count - last_processed_count) >= LLM_TRIGGER_MESSAGE_COUNT:
            logger.info(f"[{room_id}] Triggering LLM processing.")
            
            # å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
            room_ref.child("is_llm_processing").set(True)
            
            try:
                # llmApiKeyã‚’æ¸¡ã™
                agent_processing_result = await orchestrate_agents(task_payload, background_tasks, db_transcript_entries, task_payload.llmApiKey)
                
                # å‡¦ç†å®Œäº†å¾Œã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°
                room_ref.child("last_llm_processed_message_count").set(current_user_message_count)
                
                # å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
                room_ref.child("is_llm_processing").set(False)
                
                return JsonRpcResponse(result=agent_processing_result, id=request.id)
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ãƒ­ã‚°ã«è¨˜éŒ²ã—ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
                logger.error(f"[{room_id}] Error in orchestrate_agents: {e}", exc_info=True)
                
                # å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
                room_ref.child("is_llm_processing").set(False)
                
                return JsonRpcResponse(error={"code": -32000, "message": f"LLM processing error: {str(e)}"}, id=request.id)
        else:
            return JsonRpcResponse(result=AgentResult(invokedAgents=[]), id=request.id)

    except Exception as e:
        logger.error(f"Error in /invoke: {e}", exc_info=True)
        return JsonRpcResponse(error={"code": -32000, "message": f"Server error: {e}"}, id=request.id)

# ... (create_room_endpoint ã¯å¤‰æ›´ãªã—)


class CreateRoomRequest(BaseModel):
    idToken: str
    room_id: str
    room_name: Optional[str] = None
    meeting_subtitle: Optional[str] = None
    llm_api_key: Optional[str] = None
    llm_models: Optional[List[str]] = None
    speakerName: Optional[str] = None  # speakerNameã‚’è¿½åŠ 
    representativeMode: Optional[bool] = False  # ä»£è¡¨å‚åŠ è€…ãƒ¢ãƒ¼ãƒ‰
    api_key_duration_hours: Optional[int] = 24  # APIã‚­ãƒ¼ã®æŒç¶šæ™‚é–“ï¼ˆæ™‚é–“ï¼‰
    
    @field_validator('api_key_duration_hours')
    @classmethod
    def validate_api_key_duration(cls, v):
        if v is not None:
            if not isinstance(v, int):
                raise ValueError('APIã‚­ãƒ¼æŒç¶šæ™‚é–“ã¯æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„')
            if v < 1:
                raise ValueError('APIã‚­ãƒ¼æŒç¶šæ™‚é–“ã¯1æ™‚é–“ä»¥ä¸Šã§æŒ‡å®šã—ã¦ãã ã•ã„')
            if v > 8760:  # 1å¹´ = 365 * 24 = 8760æ™‚é–“
                raise ValueError('APIã‚­ãƒ¼æŒç¶šæ™‚é–“ã¯1å¹´ï¼ˆ8760æ™‚é–“ï¼‰ä»¥ä¸‹ã§æŒ‡å®šã—ã¦ãã ã•ã„')
        return v


@app.post("/create_room", summary="Create a new meeting room")
async def create_room_endpoint(request_data: CreateRoomRequest):
    room_id = request_data.room_id
    if room_id == ALLOWED_DEMO_ROOM:
        raise HTTPException(
            status_code=400, detail=f"Room ID '{ALLOWED_DEMO_ROOM}' is reserved for demo purposes.")

    room_name = request_data.room_name or f"Room {room_id}"
    try:
        decoded_token = firebase_auth.verify_id_token(request_data.idToken)
        uid = decoded_token['uid']
        user_record = firebase_auth.get_user(uid)
        # speakerNameãŒæä¾›ã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯
        display_name = request_data.speakerName or user_record.display_name or user_record.email or f"user_{uid[:5]}"

        room_ref = db.reference(f"rooms/{room_id}")
        if room_ref.get():
            # ãƒ«ãƒ¼ãƒ ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã€ä½œæˆè€…ãŒãã®ãƒ«ãƒ¼ãƒ ã®å‚åŠ è€…ã¨ã—ã¦è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if room_ref.child(f"participants/{uid}").get():
                return {"status": "success", "message": "Room already exists and you are a participant.", "data": room_ref.get()}
            else:
                # ãƒ«ãƒ¼ãƒ ã¯å­˜åœ¨ã™ã‚‹ãŒã€ä½œæˆè€…ãŒå‚åŠ è€…ã§ã¯ãªã„å ´åˆã€å‚åŠ è€…ã¨ã—ã¦è¿½åŠ 
                participant_role = "Representative" if request_data.representativeMode else "Creator"
                participant_data = {"name": display_name, "role": participant_role,
                                    "joinedAt": datetime.utcnow().isoformat() + "Z"}
                room_ref.child(f"participants/{uid}").set(participant_data)
                return {"status": "success", "message": "Room already exists, added you as a participant.", "data": room_ref.get()}

        meeting_subtitle = request_data.meeting_subtitle or ""

        # Firebase Realtime Databaseã‹ã‚‰templateãƒ«ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        template_room_ref = db.reference("rooms/template")
        template_room_data = template_room_ref.get()

        if not template_room_data:
            logger.error(
                "Template room data not found in Firebase at rooms/template")
            # templateãƒ«ãƒ¼ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€æœ€ä½é™ã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã§ãƒ«ãƒ¼ãƒ ã‚’ä½œæˆ
            logger.warning("Using minimal initial data for the new room.")
            new_room_data = {
                "sessionId": f"session_{room_id}",
                "sessionTitle": room_name,
                "meetingSubtitle": meeting_subtitle,
                "startTime": datetime.utcnow().isoformat() + "Z",
                "ownerId": uid,
                "participants": {},
                "tasks": [],
                "notes": [],
                "overviewDiagram": {"title": "ä¼šè­°ã®æ¦‚è¦å›³", "mermaidDefinition": "graph TD;\nA[ä¼šè­°é–‹å§‹];"},
                "currentAgenda": {"mainTopic": "ä¼šè­°é–‹å§‹", "details": []},
                "suggestedNextTopics": [],
                "transcript": [],
                "last_llm_processed_message_count": 0,
                "is_llm_processing": False,
                "representativeMode": request_data.representativeMode or False
            }
        else:
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã€æ–°ã—ã„ãƒ«ãƒ¼ãƒ ã®æƒ…å ±ã‚’è¨­å®š
            new_room_data = template_room_data.copy()
            new_room_data["sessionId"] = f"session_{room_id}"
            new_room_data["sessionTitle"] = room_name
            new_room_data["meetingSubtitle"] = meeting_subtitle
            new_room_data["startTime"] = datetime.utcnow().isoformat() + "Z"
            new_room_data["ownerId"] = uid
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å‚åŠ è€…ãƒªã‚¹ãƒˆã¯å¼•ãç¶™ãŒãšã€ä½œæˆè€…ã®ã¿ã‚’è¿½åŠ 
            new_room_data["participants"] = {}
            new_room_data["last_llm_processed_message_count"] = 0
            new_room_data["is_llm_processing"] = False
            new_room_data["representativeMode"] = request_data.representativeMode or False

        # ä½œæˆè€…ã‚’å‚åŠ è€…ã¨ã—ã¦è¿½åŠ 
        participant_role = "Representative" if request_data.representativeMode else "Creator"
        new_room_data["participants"][uid] = {
            "name": display_name,
            "role": participant_role,
            "joinedAt": datetime.utcnow().isoformat() + "Z"
        }

        room_ref.set(new_room_data)

        # room_secretsã«APIã‚­ãƒ¼ã¨LLMãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        room_secrets_ref = db.reference(f"room_secrets/{room_id}")
        secrets_data = {
            'created_at': datetime.utcnow().isoformat() + "Z",
            'created_by': uid
        }

        if request_data.llm_api_key:
            # APIã‚­ãƒ¼æŒç¶šæ™‚é–“ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯24æ™‚é–“ï¼‰
            duration_hours = request_data.api_key_duration_hours or 24
            key_stored_successfully = api_key_manager.store_room_api_key(
                room_id, request_data.llm_api_key, uid, duration_hours)
            if key_stored_successfully:
                # ãƒ«ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã«ã‚‚APIã‚­ãƒ¼ã®æœŸé™æƒ…å ±ã‚’ä¿å­˜
                api_key_expires_at = (datetime.utcnow() + timedelta(hours=duration_hours)).isoformat() + "Z"
                room_ref.child("apiKeyExpiresAt").set(api_key_expires_at)
                room_ref.child("apiKeyDurationHours").set(duration_hours)
                logger.info(
                    f"Room {room_id} created and LLM API Key stored in room_secrets with {duration_hours}h duration.")
            else:
                logger.warning(
                    f"Room {room_id} created, but LLM API Key could not be stored in room_secrets. Check logs for details.")
        else:
            logger.info(f"Room {room_id} created without LLM API Key.")

        if request_data.llm_models:
            secrets_data['llm_models'] = request_data.llm_models
            room_secrets_ref.update({'llm_models': request_data.llm_models})
            logger.info(
                f"Room {room_id} created and LLM models stored in room_secrets.")
        else:
            logger.info(f"Room {room_id} created without specific LLM models.")

        return {"status": "success", "message": "Room created successfully", "data": new_room_data}
    except Exception as e:
        logger.error(f"Error creating room {room_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=500, detail=f"Failed to create room: {str(e)}")


class ApproveJoinRequest(BaseModel):
    idToken: str
    roomId: str
    requesterUid: str
    action: str  # "approve" or "reject"


@app.post("/approve_join_request", summary="Approve or reject a join request for a meeting room")
async def approve_join_request_endpoint(request_data: ApproveJoinRequest):
    try:
        decoded_token = firebase_auth.verify_id_token(request_data.idToken)
        owner_uid = decoded_token['uid']

        room_ref = db.reference(f"rooms/{request_data.roomId}")
        room_data = room_ref.get()

        if not room_data:
            raise HTTPException(status_code=404, detail="Room not found.")

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ«ãƒ¼ãƒ ã®ã‚ªãƒ¼ãƒŠãƒ¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        if room_data.get("owner_uid") != owner_uid:
            raise HTTPException(
                status_code=403, detail="Only the room owner can approve/reject join requests.")

        join_requests_ref = room_ref.child("join_requests")
        requester_request = join_requests_ref.child(
            request_data.requesterUid).get()

        if not requester_request:
            raise HTTPException(
                status_code=404, detail="Join request not found for this user.")

        if request_data.action == "approve":
            # å‚åŠ è€…ã¨ã—ã¦è¿½åŠ 
            participant_data = {
                "name": requester_request.get("name", f"user_{request_data.requesterUid[:5]}"),
                "role": "Participant",
                "joinedAt": datetime.utcnow().isoformat() + "Z"
            }
            room_ref.child(
                f"participants/{request_data.requesterUid}").set(participant_data)
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
            join_requests_ref.child(request_data.requesterUid).delete()
            logger.info(
                f"User {request_data.requesterUid} approved and added to room {request_data.roomId}.")
            return {"status": "success", "message": "User approved and added to participants."}
        elif request_data.action == "reject":
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
            join_requests_ref.child(request_data.requesterUid).delete()
            logger.info(
                f"Join request for user {request_data.requesterUid} rejected for room {request_data.roomId}.")
            return {"status": "success", "message": "Join request rejected."}
        else:
            raise HTTPException(
                status_code=400, detail="Invalid action. Must be 'approve' or 'reject'.")

    except Exception as e:
        logger.error(
            f"Error in /approve_join_request for room {request_data.roomId}: {e}", exc_info=True)
        raise HTTPException(
            status_code=500, detail=f"Unexpected error: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", 8000)))
